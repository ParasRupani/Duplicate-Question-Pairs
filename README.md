

<a name="readme-top"></a>

<div align="center">

# [Duplicate Question Pair Analysis](https://github.com/ParasRupani/Duplicate-Sentence-Pairs)

<h3 align="center">    <a href="duplicate-question-pair-analysis.streamlit.app"><strong><u>Explore the Live Application via Streamlit</u> Â»</strong></a></h3>

<br>
</div>

<!-- ABOUT THE PROJECT -->
## About The Project

Duplicate question pair analysis goes beyond simple text matching; it revolves around a more comprehensive approach. Rather than focusing solely on exact text matches, we leverage NLP techniques to consider the underlying meaning and context of questions. This is achieved by utilizing methods like word embeddings and semantic similarity to identify paraphrases and conceptually related text.

This issue was initially identified by Quora, where users posed similar questions with varying wordings on the same topic. To address this, they sponsored a contest on Kaggle, challenging professionals to identify whether two questions were semantically similar or not. This problem is common across multiple platforms, including Reddit, Stack Overflow, and many more. Solving it provides domain expertise in the majority of aspects needed to implement Natural Language Processing. Overall, this project helps us strengthen our skills in the domain of NLP.

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- GETTING STARTED -->
## Getting Started



### Installation

1. Clone the repository
   ```sh
   git clone https://github.com/ParasRupani/Duplicate-Sentence-Pairs.git
   ```
2. Install the requirements
   ```sh
   pip install -r requirements.txt
   ```
3. Execute `app.py` using streamlit
   ```sh
   streamlit run streamlit_app.py
   ```

<p align="right">(<a href="#readme-top">back to top</a>)</p>


<!-- ROADMAP -->
## Steps Involved

- [x] Data Collection
    - Web Scraping
  <br>
- [x] Data Preprocessing
    - Tokenization
    - Stopwords Removal
    - POS Tagging
    - Lemmatization
    - Hashtag Removal
    - Emoji Removal
  <br>
- [x] Feature Extraction
    - TF-IDF
    - Word Embedding (GLoVe)
    - Contextual Embedding (BERT)
  <br>
- [x] Model Training
    - Logistic Regression
  <br>
- [x] Model Evaluation
    - Accuracy
    - Precision 
    - Recall 
    - F1-score
  <br>
- [x] Deployment
    - Streamlit

<p align="right">(<a href="#readme-top">back to top</a>)</p>


<!-- CONTACT -->
## Contact
Darshik - [@Darshik A Somasundaran](https://www.linkedin.com/in/darshik-a-somasundaran-b59610202/)

Hamna - [@Hamna Ashraf](https://www.linkedin.com/in/hamna-ashraf/)

Sumit - [@Sumit Sandhu](https://www.linkedin.com/in/sumit-sandhu-a642507b/)

Paras - [@ParasRupani](https://www.linkedin.com/in/ParasRupani)

Project Link: [Duplicate Question Pair Analysis](https://github.com/ParasRupani/Duplicate-Sentence-Pairs)

<p align="right">(<a href="#readme-top">back to top</a>)</p>



<!-- ACKNOWLEDGMENTS -->
## Acknowledgments
* Inspired by the Kaggle Competition hosted by [Quora - Question Pairs.](https://www.kaggle.com/competitions/quora-question-pairs)

* Comprehensive Kaggle Notebook by [Seifmechi.](https://www.kaggle.com/code/seifmechi/sentence-bert-quora-question-pairs)

