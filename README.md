

<a name="readme-top"></a>

<div align="center">

# [Duplicate Question Pair Analysis](https://github.com/ParasRupani/Duplicate-Sentence-Pairs)

<h3 align="center">    <a href="https://duplicate-question-pair-analysis.streamlit.app/"><strong><u>Explore Live Application via Streamlit</u> Â»</strong></a></h3>

<br>
</div>

<!-- ABOUT THE PROJECT -->
## About The Project

Duplicate question pair analysis goes beyond simple text matching; it revolves around a more comprehensive approach. Rather than focusing solely on exact text matches, we leverage NLP techniques to consider questions' underlying meaning and context. This is achieved by using word embeddings and semantic similarity to identify paraphrases and conceptually related text.

Quora initially identified this issue, where users posed similar questions with varying wordings on the same topic. To address this, they sponsored a contest on Kaggle, challenging professionals to identify whether the two questions were semantically similar. This problem is shared across multiple platforms, including Reddit, Stack Overflow, etc. Solving it provides domain expertise in most aspects needed to implement Natural Language Processing. Overall, this project helps us strengthen our skills in NLP.

<p align="right">(<a href="#readme-top">back to top</a>)</p>

<!-- GETTING STARTED -->
## Getting Started



### Installation

1. Clone the repository
   ```sh
   git clone https://github.com/ParasRupani/Duplicate-Sentence-Pairs.git
   ```
2. Install the requirements
   ```sh
   pip install -r requirements.txt
   ```
3. Execute `streamlit_app.py` using streamlit
   ```sh
   streamlit run streamlit_app.py
   ```

<p align="right">(<a href="#readme-top">back to top</a>)</p>


<!-- ROADMAP -->
## Steps Involved

- [x] Data Collection
    - Web Scraping
  <br>
- [x] Data Preprocessing
    - Tokenization
    - Stopwords Removal
    - POS Tagging
    - Lemmatization
    - Hashtag Removal
    - Emoji Removal
  <br>
- [x] Feature Extraction
    - TF-IDF
    - Word Embedding (GLoVe)
    - Contextual Embedding (BERT)
  <br>
- [x] Model Training
    - Logistic Regression
  <br>
- [x] Model Evaluation
    - Accuracy
    - Precision 
    - Recall 
    - F1-score
  <br>
- [x] Deployment
    - Streamlit

<p align="right">(<a href="#readme-top">back to top</a>)</p>


<!-- CONTACT -->
## Contact
Darshik - [@Darshik A Somasundaran](https://www.linkedin.com/in/darshik-a-somasundaran-b59610202/)

Hamna - [@Hamna Ashraf](https://www.linkedin.com/in/hamna-ashraf/)

Sumit - [@Sumit Sandhu](https://www.linkedin.com/in/sumit-sandhu-a642507b/)

Paras - [@ParasRupani](https://www.linkedin.com/in/ParasRupani)

Project Link: [Duplicate Question Pair Analysis](https://github.com/ParasRupani/Duplicate-Sentence-Pairs)

<p align="right">(<a href="#readme-top">back to top</a>)</p>



<!-- ACKNOWLEDGMENTS -->
## Acknowledgments
* Inspired by the Kaggle Competition hosted by [Quora - Question Pairs.](https://www.kaggle.com/competitions/quora-question-pairs)

* Comprehensive Kaggle Notebook by [Seifmechi.](https://www.kaggle.com/code/seifmechi/sentence-bert-quora-question-pairs)

